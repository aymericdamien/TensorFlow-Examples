{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Decision Tree\n",
    "\n",
    "Implement a Gradient Boosted Decision tree (GBDT) with TensorFlow to classify\n",
    "handwritten digit images. This example is using the MNIST database of\n",
    "handwritten digits as training samples (http://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "- Author: Aymeric Damien\n",
    "- Project: https://github.com/nebulaai/TensorFlow-Examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.boosted_trees.estimator_batch.estimator import GradientBoostedDecisionTreeClassifier\n",
    "from tensorflow.contrib.boosted_trees.proto import learner_pb2 as gbdt_learner\n",
    "\n",
    "# Ignore all GPUs (current TF GBDT does not support GPU).\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Import MNIST data\n",
    "# Set verbosity to display errors only (Remove this line for showing warnings)\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "data_path = \"./dataset/gradient_boosted_decision_tree/\"\n",
    "try:\n",
    "    os.makedirs(data_path)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "mnist = input_data.read_data_sets(data_path, one_hot=False,\n",
    "                                  source_url='http://yann.lecun.com/exdb/mnist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 4096 # The number of samples per batch\n",
    "num_classes = 10 # The 10 digits\n",
    "num_features = 784 # Each image is 28x28 pixels\n",
    "max_steps = 10000\n",
    "\n",
    "# GBDT Parameters\n",
    "learning_rate = 0.1\n",
    "l1_regul = 0.\n",
    "l2_regul = 1.\n",
    "examples_per_layer = 1000\n",
    "num_trees = 10\n",
    "max_depth = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill GBDT parameters into the config proto\n",
    "learner_config = gbdt_learner.LearnerConfig()\n",
    "learner_config.learning_rate_tuner.fixed.learning_rate = learning_rate\n",
    "learner_config.regularization.l1 = l1_regul\n",
    "learner_config.regularization.l2 = l2_regul / examples_per_layer\n",
    "learner_config.constraints.max_tree_depth = max_depth\n",
    "growing_mode = gbdt_learner.LearnerConfig.LAYER_BY_LAYER\n",
    "learner_config.growing_mode = growing_mode\n",
    "run_config = tf.contrib.learn.RunConfig(save_checkpoints_secs=300)\n",
    "learner_config.multi_class_strategy = (\n",
    "    gbdt_learner.LearnerConfig.DIAGONAL_HESSIAN)\\\n",
    "\n",
    "# Create a TensorFlor GBDT Estimator\n",
    "gbdt_model = GradientBoostedDecisionTreeClassifier(\n",
    "    model_dir=None, # No save directory specified\n",
    "    learner_config=learner_config,\n",
    "    n_classes=num_classes,\n",
    "    examples_per_layer=examples_per_layer,\n",
    "    num_trees=num_trees,\n",
    "    center_bias=False,\n",
    "    config=run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Display TF info logs\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.train.images}, y=mnist.train.labels,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "\n",
    "# Train the Model\n",
    "gbdt_model.fit(input_fn=input_fn, max_steps=max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "# Define the input function for evaluating\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': mnist.test.images}, y=mnist.test.labels,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Use the Estimator 'evaluate' method\n",
    "e = gbdt_model.evaluate(input_fn=input_fn)\n",
    "print(\"Testing Accuracy:\", e['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
