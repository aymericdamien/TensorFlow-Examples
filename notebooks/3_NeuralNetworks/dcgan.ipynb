{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Generative Adversarial Network Example\n",
    "\n",
    "Build a deep convolutional generative adversarial network (DCGAN) to generate digit images from a noise distribution with TensorFlow.\n",
    "\n",
    "- Author: Aymeric Damien\n",
    "- Project: https://github.com/nebulaai/TensorFlow-Examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN Overview\n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/45e147fc9dfcf6a8e5df2c9b985078258b9974e3/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f313030302f312a33394e6e6e695f6e685044614c7539416e544c6f57772e706e67\" alt=\"dcgan\" style=\"width: 1000px;\"/>\n",
    "\n",
    "References:\n",
    "- [Unsupervised representation learning with deep convolutional generative adversarial networks](https://arxiv.org/pdf/1511.06434). A Radford, L Metz, S Chintala, 2016.\n",
    "- [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a.html). X Glorot, Y Bengio. Aistats 9, 249-256\n",
    "- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167). Sergey Ioffe, Christian Szegedy. 2015.\n",
    "\n",
    "## MNIST Dataset Overview\n",
    "\n",
    "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. For simplicity, each image has been flattened and converted to a 1-D numpy array of 784 features (28*28).\n",
    "\n",
    "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "More info: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   \n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data_path = \"./dataset/dcgan/\"\n",
    "try:\n",
    "    os.makedirs(data_path)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "mnist = input_data.read_data_sets(data_path, one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Training Params\n",
    "num_steps = 10000\n",
    "batch_size = 128\n",
    "lr_generator = 0.002\n",
    "lr_discriminator = 0.002\n",
    "\n",
    "# Network Params\n",
    "image_dim = 784 # 28*28 pixels * 1 channel\n",
    "noise_dim = 100 # Noise data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Build Networks\n",
    "# Network Inputs\n",
    "noise_input = tf.placeholder(tf.float32, shape=[None, noise_dim])\n",
    "real_image_input = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n",
    "# A boolean to indicate batch normalization if it is training or inference time\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "#LeakyReLU activation\n",
    "def leakyrelu(x, alpha=0.2):\n",
    "    return 0.5 * (1 + alpha) * x + 0.5 * (1 - alpha) * abs(x)\n",
    "\n",
    "# Generator Network\n",
    "# Input: Noise, Output: Image\n",
    "# Note that batch normalization has different behavior at training and inference time,\n",
    "# we then use a placeholder to indicates the layer if we are training or not.\n",
    "def generator(x, reuse=False):\n",
    "    with tf.variable_scope('Generator', reuse=reuse):\n",
    "        # TensorFlow Layers automatically create variables and calculate their\n",
    "        # shape, based on the input.\n",
    "        x = tf.layers.dense(x, units=7 * 7 * 128)\n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        x = tf.nn.relu(x)\n",
    "        # Reshape to a 4-D array of images: (batch, height, width, channels)\n",
    "        # New shape: (batch, 7, 7, 128)\n",
    "        x = tf.reshape(x, shape=[-1, 7, 7, 128])\n",
    "        # Deconvolution, image shape: (batch, 14, 14, 64)\n",
    "        x = tf.layers.conv2d_transpose(x, 64, 5, strides=2, padding='same')\n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        x = tf.nn.relu(x)\n",
    "        # Deconvolution, image shape: (batch, 28, 28, 1)\n",
    "        x = tf.layers.conv2d_transpose(x, 1, 5, strides=2, padding='same')\n",
    "        # Apply tanh for better stability - clip values to [-1, 1].\n",
    "        x = tf.nn.tanh(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Discriminator Network\n",
    "# Input: Image, Output: Prediction Real/Fake Image\n",
    "def discriminator(x, reuse=False):\n",
    "    with tf.variable_scope('Discriminator', reuse=reuse):\n",
    "        # Typical convolutional neural network to classify images.\n",
    "        x = tf.layers.conv2d(x, 64, 5, strides=2, padding='same')\n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        x = leakyrelu(x)\n",
    "        x = tf.layers.conv2d(x, 128, 5, strides=2, padding='same')\n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        x = leakyrelu(x)\n",
    "        # Flatten\n",
    "        x = tf.reshape(x, shape=[-1, 7*7*128])\n",
    "        x = tf.layers.dense(x, 1024)\n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        x = leakyrelu(x)\n",
    "        # Output 2 classes: Real and Fake images\n",
    "        x = tf.layers.dense(x, 2)\n",
    "    return x\n",
    "\n",
    "# Build Generator Network\n",
    "gen_sample = generator(noise_input)\n",
    "\n",
    "# Build 2 Discriminator Networks (one from noise input, one from generated samples)\n",
    "disc_real = discriminator(real_image_input)\n",
    "disc_fake = discriminator(gen_sample, reuse=True)\n",
    "\n",
    "# Build the stacked generator/discriminator\n",
    "stacked_gan = discriminator(gen_sample, reuse=True)\n",
    "\n",
    "# Build Loss (Labels for real images: 1, for fake images: 0)\n",
    "# Discriminator Loss for real and fake samples\n",
    "disc_loss_real = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=disc_real, labels=tf.ones([batch_size], dtype=tf.int32)))\n",
    "disc_loss_fake = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=disc_fake, labels=tf.zeros([batch_size], dtype=tf.int32)))\n",
    "# Sum both loss\n",
    "disc_loss = disc_loss_real + disc_loss_fake\n",
    "# Generator Loss (The generator tries to fool the discriminator, thus labels are 1)\n",
    "gen_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=stacked_gan, labels=tf.ones([batch_size], dtype=tf.int32)))\n",
    "\n",
    "# Build Optimizers\n",
    "optimizer_gen = tf.train.AdamOptimizer(learning_rate=lr_generator, beta1=0.5, beta2=0.999)\n",
    "optimizer_disc = tf.train.AdamOptimizer(learning_rate=lr_discriminator, beta1=0.5, beta2=0.999)\n",
    "\n",
    "# Training Variables for each optimizer\n",
    "# By default in TensorFlow, all variables are updated by each optimizer, so we\n",
    "# need to precise for each one of them the specific variables to update.\n",
    "# Generator Network Variables\n",
    "gen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Generator')\n",
    "# Discriminator Network Variables\n",
    "disc_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Discriminator')\n",
    "\n",
    "# Create training operations\n",
    "# TensorFlow UPDATE_OPS collection holds all batch norm operation to update the moving mean/stddev\n",
    "gen_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope='Generator')\n",
    "# `control_dependencies` ensure that the `gen_update_ops` will be run before the `minimize` op (backprop)\n",
    "with tf.control_dependencies(gen_update_ops):\n",
    "    train_gen = optimizer_gen.minimize(gen_loss, var_list=gen_vars)\n",
    "disc_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope='Discriminator')\n",
    "with tf.control_dependencies(disc_update_ops):\n",
    "    train_disc = optimizer_disc.minimize(disc_loss, var_list=disc_vars)\n",
    "    \n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Start Training\n",
    "# Start a new TF session\n",
    "\n",
    "# sess = tf.Session()\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init)\n",
    "    \n",
    "# Training\n",
    "for i in range(1, num_steps+1):\n",
    "\n",
    "    # Prepare Input Data\n",
    "    # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "    batch_x, _ = mnist.train.next_batch(batch_size)\n",
    "    batch_x = np.reshape(batch_x, newshape=[-1, 28, 28, 1])\n",
    "    # Rescale to [-1, 1], the input range of the discriminator\n",
    "    batch_x = batch_x * 2. - 1.\n",
    "\n",
    "    # Discriminator Training\n",
    "    # Generate noise to feed to the generator\n",
    "    z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n",
    "    _, dl = sess.run([train_disc, disc_loss], feed_dict={real_image_input: batch_x, noise_input: z, is_training:True})\n",
    "    \n",
    "    # Generator Training\n",
    "    # Generate noise to feed to the generator\n",
    "    z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n",
    "    _, gl = sess.run([train_gen, gen_loss], feed_dict={noise_input: z, is_training:True})\n",
    "    \n",
    "    if i % 500 == 0 or i == 1:\n",
    "        print('Step %i: Generator Loss: %f, Discriminator Loss: %f' % (i, gl, dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "# Generate images from noise, using the generator network.\n",
    "n = 6\n",
    "canvas = np.empty((28 * n, 28 * n))\n",
    "for i in range(n):\n",
    "    # Noise input.\n",
    "    z = np.random.uniform(-1., 1., size=[n, noise_dim])\n",
    "    # Generate image from noise.\n",
    "    g = sess.run(gen_sample, feed_dict={noise_input: z, is_training:False})\n",
    "    # Rescale values to the original [0, 1] (from tanh -> [-1, 1])\n",
    "    g = (g + 1.) / 2.\n",
    "    # Reverse colours for better display\n",
    "    g = -1 * (g - 1)\n",
    "    for j in range(n):\n",
    "        # Draw the generated digits\n",
    "        canvas[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = g[j].reshape([28, 28])\n",
    "\n",
    "plt.figure(figsize=(n, n))\n",
    "plt.imshow(canvas, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
