{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Auto-Encoder Example\n",
    "\n",
    "Build a variational auto-encoder (VAE) to generate digit images from a noise distribution with TensorFlow.\n",
    "\n",
    "- Author: Aymeric Damien\n",
    "- Project: https://github.com/nebulaai/TensorFlow-Examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE Overview\n",
    "\n",
    "<img src=\"http://kvfrans.com/content/images/2016/08/vae.jpg\" alt=\"vae\" style=\"width: 800px;\"/>\n",
    "\n",
    "References:\n",
    "- [Auto-Encoding Variational Bayes The International Conference on Learning Representations](https://arxiv.org/abs/1312.6114) (ICLR), Banff, 2014. D.P. Kingma, M. Welling\n",
    "- [Understanding the difficulty of training deep feedforward neural networks](www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.../AISTATS2010_Glorot.pdf). X Glorot, Y Bengio. Aistats 9, 249-256\n",
    "\n",
    "Other tutorials:\n",
    "- [Variational Auto Encoder Explained](http://kvfrans.com/variational-autoencoders-explained/). Kevin Frans.\n",
    "\n",
    "## MNIST Dataset Overview\n",
    "\n",
    "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. For simplicity, each image has been flattened and converted to a 1-D numpy array of 784 features (28*28).\n",
    "\n",
    "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "More info: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data_path = \"./dataset/variation_autoencoder/\"\n",
    "try:\n",
    "    os.makedirs(data_path)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "mnist = input_data.read_data_sets(data_path, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 30000\n",
    "batch_size = 64\n",
    "\n",
    "# Network Parameters\n",
    "image_dim = 784 # MNIST images are 28x28 pixels\n",
    "hidden_dim = 512\n",
    "latent_dim = 2\n",
    "\n",
    "# A custom initialization (see Xavier Glorot init)\n",
    "def glorot_init(shape):\n",
    "    return tf.random_normal(shape=shape, stddev=1. / tf.sqrt(shape[0] / 2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(glorot_init([image_dim, hidden_dim])),\n",
    "    'z_mean': tf.Variable(glorot_init([hidden_dim, latent_dim])),\n",
    "    'z_std': tf.Variable(glorot_init([hidden_dim, latent_dim])),\n",
    "    'decoder_h1': tf.Variable(glorot_init([latent_dim, hidden_dim])),\n",
    "    'decoder_out': tf.Variable(glorot_init([hidden_dim, image_dim]))\n",
    "}\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(glorot_init([hidden_dim])),\n",
    "    'z_mean': tf.Variable(glorot_init([latent_dim])),\n",
    "    'z_std': tf.Variable(glorot_init([latent_dim])),\n",
    "    'decoder_b1': tf.Variable(glorot_init([hidden_dim])),\n",
    "    'decoder_out': tf.Variable(glorot_init([image_dim]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the encoder\n",
    "input_image = tf.placeholder(tf.float32, shape=[None, image_dim])\n",
    "encoder = tf.matmul(input_image, weights['encoder_h1']) + biases['encoder_b1']\n",
    "encoder = tf.nn.tanh(encoder)\n",
    "z_mean = tf.matmul(encoder, weights['z_mean']) + biases['z_mean']\n",
    "z_std = tf.matmul(encoder, weights['z_std']) + biases['z_std']\n",
    "\n",
    "# Sampler: Normal (gaussian) random distribution\n",
    "eps = tf.random_normal(tf.shape(z_std), dtype=tf.float32, mean=0., stddev=1.0,\n",
    "                       name='epsilon')\n",
    "z = z_mean + tf.exp(z_std / 2) * eps\n",
    "\n",
    "# Building the decoder (with scope to re-use these layers later)\n",
    "decoder = tf.matmul(z, weights['decoder_h1']) + biases['decoder_b1']\n",
    "decoder = tf.nn.tanh(decoder)\n",
    "decoder = tf.matmul(decoder, weights['decoder_out']) + biases['decoder_out']\n",
    "decoder = tf.nn.sigmoid(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define VAE Loss\n",
    "def vae_loss(x_reconstructed, x_true):\n",
    "    # Reconstruction losshttps://notebook.nbai.io/user/shogan@nbai.io/notebooks/work/notebook/3_NeuralNetworks/variational_autoencoder_ok.ipynb#\n",
    "    encode_decode_loss = x_true * tf.log(1e-10 + x_reconstructed) \\\n",
    "                         + (1 - x_true) * tf.log(1e-10 + 1 - x_reconstructed)\n",
    "    encode_decode_loss = -tf.reduce_sum(encode_decode_loss, 1)\n",
    "    # KL Divergence loss\n",
    "    kl_div_loss = 1 + z_std - tf.square(z_mean) - tf.exp(z_std)\n",
    "    kl_div_loss = -0.5 * tf.reduce_sum(kl_div_loss, 1)\n",
    "    return tf.reduce_mean(encode_decode_loss + kl_div_loss)\n",
    "\n",
    "loss_op = vae_loss(decoder, input_image)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Training\n",
    "# Start a new TF session\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init)\n",
    "\n",
    "# Training\n",
    "for i in range(1, num_steps+1):\n",
    "    # Prepare Data\n",
    "    # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "    batch_x, _ = mnist.train.next_batch(batch_size)\n",
    "\n",
    "    # Train\n",
    "    feed_dict = {input_image: batch_x}\n",
    "    _, l = sess.run([train_op, loss_op], feed_dict=feed_dict)\n",
    "    if i % 1000 == 0 or i == 1:\n",
    "        print('Step %i, Loss: %f' % (i, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "# Generator takes noise as input\n",
    "noise_input = tf.placeholder(tf.float32, shape=[None, latent_dim])\n",
    "# Rebuild the decoder to create image from noise\n",
    "decoder = tf.matmul(noise_input, weights['decoder_h1']) + biases['decoder_b1']\n",
    "decoder = tf.nn.tanh(decoder)\n",
    "decoder = tf.matmul(decoder, weights['decoder_out']) + biases['decoder_out']\n",
    "decoder = tf.nn.sigmoid(decoder)\n",
    "\n",
    "# Building a manifold of generated digits\n",
    "n = 20\n",
    "x_axis = np.linspace(-3, 3, n)\n",
    "y_axis = np.linspace(-3, 3, n)\n",
    "\n",
    "canvas = np.empty((28 * n, 28 * n))\n",
    "for i, yi in enumerate(x_axis):\n",
    "    for j, xi in enumerate(y_axis):\n",
    "        z_mu = np.array([[xi, yi]] * batch_size)\n",
    "        x_mean = sess.run(decoder, feed_dict={noise_input: z_mu})\n",
    "        canvas[(n - i - 1) * 28:(n - i) * 28, j * 28:(j + 1) * 28] = \\\n",
    "        x_mean[0].reshape(28, 28)\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "Xi, Yi = np.meshgrid(x_axis, y_axis)\n",
    "plt.imshow(canvas, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
