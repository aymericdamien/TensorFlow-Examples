{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Example\n",
    "\n",
    "Build a 2-hidden layers fully connected neural network (a.k.a multilayer perceptron) with TensorFlow v2.\n",
    "\n",
    "This example is using a low-level approach to better understand all mechanics behind building neural networks and the training process.\n",
    "\n",
    "- Author: Miguel Tomás\n",
    "- Project: https://github.com/aeonSolutions/TensorFlow-Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Overview\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" alt=\"nn\" style=\"width: 400px;\"/>\n",
    "\n",
    "This example is using a file csv dataset.  \n",
    "\n",
    "In this example, each dataset will be converted to float32, normalized to [0, 1] and flattened to a 1-D array of \"num_features\" features \n",
    "\n",
    "More info: https://github.com/aeonSolutions/TensorFlow-Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualize predictions.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters initialization.\n",
    "num_classes = 100 # total classes : number of output results\n",
    "num_features = 0 # data features : number of samples(rows) for the variable set. a value of 0 loads from the dataset bellow\n",
    "\n",
    "# Training parameters.\n",
    "learning_rate = 1\n",
    "training_steps = 10000\n",
    "batch_size = 150\n",
    "display_step = 100\n",
    "\n",
    "#normalization of data\n",
    "normalizeDataValues=True\n",
    "normalizationType= \"mean\" # accepts: max, mean\n",
    "normalizationTypeBinary=True\n",
    "\n",
    "# Network parameters.\n",
    "n_hidden_1 = 512 # 1st layer number of neurons.\n",
    "n_hidden_2 = 512 # 2nd layer number of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions Data.\n",
    "df_predict_ds=pd.read_csv('./week3_exam_dataset_test.csv')\n",
    "\n",
    "data_predict_x = np.float32(df_predict_ds.values)\n",
    "\n",
    "# Training Data.\n",
    "df_tr=pd.read_csv('./week3_exam_dataset_train.csv')\n",
    "\n",
    "df_tr_raw_y= df_tr['y']\n",
    "if num_classes==0:\n",
    "    num_classes= df_tr_raw_y.shape[0]\n",
    "if num_features==0:\n",
    "    num_features= df_tr_raw_y.shape[0]\n",
    "else:\n",
    "    rs=\"\"\n",
    "    #TODO: fill possible empty values on the datasets\n",
    "    \n",
    "df_tr_raw_values_y = df_tr_raw_y.values\n",
    "data_tr_y = np.float32(df_tr_raw_values_y)\n",
    "\n",
    "df_tr_raw_x= df_tr.drop('y',1)\n",
    "df_tr_raw_values_x = df_tr_raw_x.values\n",
    "data_tr_x = np.float32(df_tr_raw_values_x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_tr_raw_x, df_tr_raw_y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Convert to float32.\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "# Convert to float32.\n",
    "y_train, y_test = np.array(y_train, np.float32), np.array(y_test, np.float32)\n",
    "\n",
    "# Normalize data values to [0, 1] interval.\n",
    "if normalizeDataValues:\n",
    "    if normalizationType==\"max\":\n",
    "        maxVal_train=np.amax(x_train, axis=0)\n",
    "        maxVal_test=np.amax(x_test, axis=0)\n",
    "        maxVal_pred=np.amax(data_predict_x, axis=0)\n",
    "        maxVal=max(np.amax(maxVal_train, axis=0),np.amax(maxVal_test, axis=0),np.amax(maxVal_pred, axis=0))\n",
    "        if normalizationTypeBinary:\n",
    "            x_train, x_test,data_predict_x = np.where((x_train / maxVal_train)>=0.5,1,0), np.where((x_test / maxVal_test)>=0.5,1,0), np.where((data_predict_x / maxVal_pred)>=0.5,1,0)\n",
    "        else:\n",
    "            x_train, x_test, data_predict_x = x_train / maxVal_train, x_test / maxVal_test, data_predict_x / maxVal_pred\n",
    "    else:\n",
    "        meanVal_test=np.mean(x_test, axis=0)\n",
    "        meanVal_train=np.mean(x_train, axis=0)\n",
    "        meanVal_pred=np.mean(data_predict_x, axis=0)\n",
    "        meanVal=max(np.amax(meanVal_train, axis=0),np.amax(meanVal_test, axis=0),np.amax(meanVal_pred, axis=0))\n",
    "        \n",
    "        if normalizationTypeBinary:\n",
    "            x_train, x_test,data_predict_x = np.where((x_train / meanVal_train)>=0.5,1,0), np.where((x_test / meanVal_test)>=0.5,1,0), np.where((data_predict_x / meanVal_pred)>=0.5,1,0)\n",
    "        else:\n",
    "            x_train, x_test, data_predict_x = x_train / meanVal_train, x_test / meanVal_test, data_predict_x / meanVal_pred\n",
    "\n",
    "# Use tf.data API to shuffle and batch data.\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF Model.\n",
    "class NeuralNet(Model):\n",
    "    # Set layers.\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # First fully-connected hidden layer.\n",
    "        self.fc1 = layers.Dense(n_hidden_1, activation=tf.nn.relu)\n",
    "        # First fully-connected hidden layer.\n",
    "        self.fc2 = layers.Dense(n_hidden_2, activation=tf.nn.relu)\n",
    "        # Second fully-connecter hidden layer.\n",
    "        self.out = layers.Dense(num_classes)\n",
    "\n",
    "    # Set forward pass.\n",
    "    def call(self, x, is_training=False):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        if not is_training:\n",
    "            # tf cross entropy expect logits without softmax, so only\n",
    "            # apply softmax when not training.\n",
    "            x = tf.nn.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Build neural network model.\n",
    "neural_net = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Entropy Loss.\n",
    "# Note that this will apply 'softmax' to the logits.\n",
    "def cross_entropy_loss(x, y):\n",
    "    # Convert labels to int 64 for tf cross-entropy function.\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    # Apply softmax to logits and compute cross-entropy.\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)\n",
    "    # Average loss across the batch.\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# Accuracy metric.\n",
    "def accuracy(y_pred, y_true):\n",
    "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
    "\n",
    "# Accuracy metric.\n",
    "def accuracyAvg(y_pred):\n",
    "    print(y_pred.numpy().shape)\n",
    "    \n",
    "    #convert to 1D array\n",
    "    y_pred_1d_array= y_pred.ravel()\n",
    "    \n",
    "    accCalc= np.full(y_pred_1d_array.shape, 0)\n",
    "    delta=np.amax(real_y_1d_array)-np.amin(real_y_1d_array)\n",
    "    \n",
    "    for i in range(len(y_pred_1d_array)):\n",
    "        accCalc[i]= abs(delta-y_pred_1d_array[i] - real_y_1d_array[i])\n",
    "    \n",
    "    return accCalc\n",
    "\n",
    "# Stochastic gradient descent optimizer.\n",
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization process. \n",
    "def run_optimization(x, y):\n",
    "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
    "    with tf.GradientTape() as g:\n",
    "        # Forward pass.\n",
    "        pred = neural_net(x, is_training=True)\n",
    "        # Compute loss.\n",
    "        loss = cross_entropy_loss(pred, y)\n",
    "        \n",
    "    # Variables to update, i.e. trainable variables.\n",
    "    trainable_variables = neural_net.trainable_variables\n",
    "\n",
    "    # Compute gradients.\n",
    "    gradients = g.gradient(loss, trainable_variables)\n",
    "    \n",
    "    # Update W and b following gradients.\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "def live_plot(steps, accuracy, figsize=(7,5), title=''):\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.xlim(0, training_steps)\n",
    "    plt.ylim(0, 100)\n",
    "    steps= [float(i) for i in steps]\n",
    "    accuracy= [float(i) for i in accuracy]\n",
    "    \n",
    "    m=0\n",
    "    if len(steps) > 1:\n",
    "        plt.scatter(steps,accuracy, label='accuracy', color='k') \n",
    "        m, b = np.polyfit(steps, accuracy, 1)\n",
    "        plt.plot(steps, [x * m for x in steps] + b)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy %')\n",
    "    #plt.legend(loc='center left') # the plot evolves to the right\n",
    "    plt.show();\n",
    "    return m\n",
    "\n",
    "def ETC(start, steps):\n",
    "    time_elapsed = datetime.now() - start\n",
    "    eta= (training_steps-steps) / display_step * time_elapsed\n",
    "    #avgString = str(avg).split(\".\")[0]\n",
    "    \n",
    "    hours= int(eta.seconds/3600)\n",
    "    minutes= int((eta.seconds/60)-hours*60)\n",
    "    seconds = int(eta.seconds - minutes*60 -hours*3600)\n",
    "    return \"%sh, %s min and %s sec\" % (hours, minutes, seconds)\n",
    "\n",
    "def elapsedTime(elapsed):\n",
    "    hours= int(elapsed.seconds/3600)\n",
    "    minutes= int((elapsed.seconds/60)-hours*60)\n",
    "    seconds = int(elapsed.seconds - minutes*60 -hours*3600)\n",
    "    return \"%sh, %s min and %s sec\" % (hours, minutes, seconds)\n",
    "\n",
    "def progress(percent=0, width=30):\n",
    "    left = width * percent // 100\n",
    "    right = width - left\n",
    "    print('\\r[', '#' * left, ' ' * right, ']',\n",
    "          f' {percent:.0f}%\\n',\n",
    "          sep='', end='', flush=True)\n",
    "    \n",
    "def measureSkewness(series):    \n",
    "    result=\"\"\n",
    "    \n",
    "    if (series.skew() > 1 or series.skew() < -1):\n",
    "        result=\"Highly skewed distribution\"\n",
    "    elif((0.5 < series.skew() < 1) or (-1 < series.skew() < -0.5)):\n",
    "        result=\"Moderately skewed distribution\"\n",
    "    elif(-0.5 < series.skew() < 0.5):\n",
    "        result=\"Approximately symmetric distribution\"\n",
    "    result = result +\" ( \" +str(round(series.skew(),2))+\" )\"\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##############################] 100%\n",
      "\n",
      "================= Iteration Stats ================\n",
      "                   step: 10000 of 10000\n",
      "                   loss: 0.403381\n",
      "\n",
      "               accuracy: 82.00 %\n",
      "                    AVG: 82.22 %\n",
      "                   Best: 89.33 %\n",
      "\n",
      "            Trend slope: 0.000\n",
      "         MAD Dispersion: nan\n",
      "               Skewness: Approximately symmetric distribution ( -0.22 )\n",
      "\n",
      "================= Time           ================\n",
      "                Elapsed: 0h, 2 min and 30 sec\n",
      "                    ETC: 0h, 0 min and 0 sec\n",
      "\n",
      "================= Network Setup  ================\n",
      "      number of classes: 100\n",
      "     number of features: 32460\n",
      "          learning rate: 1\n",
      "         training steps: 10000\n",
      "             batch size: 150\n",
      "1st layer n. of neurons: 512\n",
      "2st layer n. of neurons: 512\n",
      "        Normalized data: True, type: mean, Discrete Binary 0/1\n",
      "\n",
      "Analysis finished.\n"
     ]
    }
   ],
   "source": [
    "# Run training for the given number of steps.\n",
    "avgCounter=0\n",
    "avg=0.0\n",
    "\n",
    "steps=[]\n",
    "accuracyValue=[]\n",
    "\n",
    "start_time = datetime.now()\n",
    "totalStartTime=start_time\n",
    "    \n",
    "live_plot([0], [0])\n",
    "print(\"analysis started. Waiting for preliminary data. One moment please...\")\n",
    "progress(0) \n",
    "\n",
    "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
    "    # Run the optimization to update W and b values.\n",
    "    run_optimization(batch_x, batch_y)\n",
    "        \n",
    "    if step % display_step == 0:\n",
    "        pred = neural_net(batch_x, is_training=True)\n",
    "        loss = cross_entropy_loss(pred, batch_y)\n",
    "        acc = accuracy(pred, batch_y)\n",
    "        avgCounter+=1\n",
    "        avg+=acc*100\n",
    "        \n",
    "        steps.append(step)\n",
    "        accuracyValue.append(acc*100)\n",
    "        trendSlope= live_plot(steps, accuracyValue)\n",
    "        totalTime =datetime.now()- totalStartTime\n",
    "        \n",
    "        stats=pd.Series(accuracyValue)\n",
    "        \n",
    "        if int(step/training_steps*100)<100:\n",
    "            print(\"Running...\")\n",
    "        progress(int(step/training_steps*100)) \n",
    "        print(\"\")\n",
    "        print(\"================= Iteration Stats ================\")\n",
    "        print(\"                   step: %i of %i\" % (step,training_steps))\n",
    "        print(\"                   loss: %f\" % loss)\n",
    "        print(\"\")\n",
    "        print(\"               accuracy: %.2f %%\" %  (acc*100))\n",
    "        print(\"                    AVG: %.2f %%\" % (avg/avgCounter))\n",
    "        print(\"                   Best: %.2f %%\" % (np.max(accuracyValue)))\n",
    "        print(\"\")\n",
    "        print(\"            Trend slope: %.3f\" % (trendSlope))\n",
    "        print(\"         MAD Dispersion: \" + str(stats.mad()))\n",
    "        print(\"               Skewness: \" + measureSkewness(stats))\n",
    "        print(\"\")\n",
    "        print(\"================= Time           ================\")\n",
    "        print(\"                Elapsed: \" + elapsedTime(totalTime))\n",
    "        print(\"                    ETC: \" + ETC(start_time,step))\n",
    "        print(\"\")\n",
    "        print(\"================= Network Setup  ================\")\n",
    "        print(\"      number of classes: \"+ str(num_classes))\n",
    "        print(\"     number of features: \"+ str(num_features)) \n",
    "\n",
    "        print(\"          learning rate: \"+ str(learning_rate))\n",
    "        print(\"         training steps: \"+ str(training_steps))\n",
    "        print(\"             batch size: \"+ str(batch_size))\n",
    "\n",
    "        print(\"1st layer n. of neurons: \"+ str(n_hidden_1 ))\n",
    "        print(\"2st layer n. of neurons: \"+ str(n_hidden_2))\n",
    "        print(\"        Normalized data: \" + (\"True\" if normalizeDataValues else \"False\") +\", type: \" + normalizationType +\", \" +(\"Discrete Binary 0/1\" if normalizationType else \"Continuous range [0,1]\"))\n",
    "\n",
    "        start_time = datetime.now()\n",
    "print(\"\")\n",
    "print(\"Analysis finished.\")        \n",
    "#print(\"Final Average accuracy is %.2f %%\" % (avg/avgCounter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#!!! code bellow this line is not yet finished !!!\n",
    "# +++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "# Test model on validation set.\n",
    "print(x_test.shape)\n",
    "\n",
    "pred = neural_net(x_test, is_training=False)\n",
    "\n",
    "print(\"Accuracy of highest score in prediction vector\")\n",
    "print(\"         Test Accuracy: %.2f %%\" % (tf.math.round(100*accuracy(pred, y_test))))\n",
    "print(\"\")\n",
    "\n",
    "prediction= np.round(pred.numpy(),2)\n",
    "print(\"Model prediction shape:\"  + str(prediction.shape))\n",
    "print(\"   Model initial shape:\"  + str(y_test.shape))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Model prediction value:\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = neural_net(data_predict_x)\n",
    "print(\"Model prediction: %i\" % np.argmax(predictions.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Author: Miguel Tomás \n",
    "\n",
    " License: Creative Commons \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
