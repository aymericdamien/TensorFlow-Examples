{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Example\n",
    "\n",
    "Build a 2-hidden layers fully connected neural network (a.k.a multilayer perceptron) with TensorFlow v2.\n",
    "\n",
    "This example is using a low-level approach to better understand all mechanics behind building neural networks and the training process.\n",
    "\n",
    "- Author: Miguel Tom√°s\n",
    "- Project: https://github.com/aeonSolutions/TensorFlow-Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Overview\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" alt=\"nn\" style=\"width: 400px;\"/>\n",
    "\n",
    "This example is using a file csv dataset.  \n",
    "\n",
    "In this example, each dataset will be converted to float32, normalized to [0, 1] and flattened to a 1-D array of \"num_features\" features \n",
    "\n",
    "More info: https://github.com/aeonSolutions/TensorFlow-Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualize predictions.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task type to perform\n",
    "taskRunning=\"classification\" # can be: classification / regression\n",
    "\n",
    "#normalization of data\n",
    "normalizeDataValues=True\n",
    "normalizationType= \"max\" # accepts: max, mean\n",
    "normalizationTypeBinary=True\n",
    "\n",
    "# parameters initialization.\n",
    "num_classes = 1 # total classes : number of output results wanted\n",
    "num_features = 0 # data features : number of input variables on the dataset. a value of 0 loads from the dataset bellow\n",
    "\n",
    "# Training parameters.\n",
    "learning_rate = 0.0000001\n",
    "training_steps = 5000\n",
    "batch_size = 100\n",
    "display_step = 100\n",
    "\n",
    "# Network parameters.\n",
    "n_hidden_1 = 256 # 1st layer number of neurons.\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions Data.\n",
    "df_predict_ds=pd.read_csv('./week3_exam_dataset_test.csv')\n",
    "\n",
    "data_predict_x = np.float32(df_predict_ds.values)\n",
    "\n",
    "# Training Data.\n",
    "df_tr=pd.read_csv('./week3_exam_dataset_train.csv')\n",
    "\n",
    "df_tr_raw_y= df_tr['y']\n",
    "\n",
    "df_tr_raw_values_y = df_tr_raw_y.values\n",
    "data_tr_y = np.float32(df_tr_raw_values_y)\n",
    "\n",
    "df_tr_raw_x= df_tr.drop('y',1)\n",
    "if num_features==0:\n",
    "    num_features= df_tr_raw_x.shape[1]\n",
    "else:\n",
    "    rs=\"\"\n",
    "    #TODO: fill possible empty values on the datasets\n",
    "df_tr_raw_values_x = df_tr_raw_x.values\n",
    "data_tr_x = np.float32(df_tr_raw_values_x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_tr_raw_x, df_tr_raw_y, test_size=0.33, random_state=1)\n",
    "\n",
    "# Convert to float32.\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "# Convert to float32.\n",
    "y_train, y_test = np.array(y_train, np.float32), np.array(y_test, np.float32)\n",
    "\n",
    "# Normalize data values to [0, 1] interval.\n",
    "if normalizeDataValues:\n",
    "    if normalizationType==\"max\":\n",
    "        maxVal_train=np.amax(x_train, axis=0)\n",
    "        maxVal_test=np.amax(x_test, axis=0)\n",
    "        maxVal_pred=np.amax(data_predict_x, axis=0)\n",
    "        maxVal=max(np.amax(maxVal_train, axis=0),np.amax(maxVal_test, axis=0),np.amax(maxVal_pred, axis=0))\n",
    "        if normalizationTypeBinary:\n",
    "            x_train, x_test,data_predict_x = np.where((x_train / maxVal_train)>=0.5,1,0), np.where((x_test / maxVal_test)>=0.5,1,0), np.where((data_predict_x / maxVal_pred)>=0.5,1,0)\n",
    "        else:\n",
    "            x_train, x_test, data_predict_x = x_train / maxVal_train, x_test / maxVal_test, data_predict_x / maxVal_pred\n",
    "    else:\n",
    "        meanVal_test=np.mean(x_test, axis=0)\n",
    "        meanVal_train=np.mean(x_train, axis=0)\n",
    "        meanVal_pred=np.mean(data_predict_x, axis=0)\n",
    "        meanVal=max(np.amax(meanVal_train, axis=0),np.amax(meanVal_test, axis=0),np.amax(meanVal_pred, axis=0))\n",
    "        \n",
    "        if normalizationTypeBinary:\n",
    "            x_train, x_test,data_predict_x = np.where((x_train / meanVal_train)>=0.5,1,0), np.where((x_test / meanVal_test)>=0.5,1,0), np.where((data_predict_x / meanVal_pred)>=0.5,1,0)\n",
    "        else:\n",
    "            x_train, x_test, data_predict_x = x_train / meanVal_train, x_test / meanVal_test, data_predict_x / meanVal_pred\n",
    "\n",
    "# Use tf.data API to shuffle and batch data.\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF Model.\n",
    "class NeuralNet(Model):\n",
    "    # Set layers.\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # First fully-connected hidden layer.\n",
    "        self.fc1 = layers.Dense(n_hidden_1, activation=tf.nn.relu)\n",
    "        # First fully-connected hidden layer.\n",
    "        self.fc2 = layers.Dense(n_hidden_2, activation=tf.nn.relu)\n",
    "        # Second fully-connecter hidden layer.\n",
    "        if (taskRunning==\"classification\"):\n",
    "            self.out = layers.Dense(num_classes+1)\n",
    "        else:\n",
    "            self.out = layers.Dense(num_classes)\n",
    "            \n",
    "    # Set forward pass.\n",
    "    def call(self, x, is_training=False):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        if not is_training:\n",
    "            # tf cross entropy expect logits without softmax, so only\n",
    "            # apply softmax when not training.\n",
    "            x = tf.nn.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Build neural network model.\n",
    "neural_net = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Entropy Loss.\n",
    "# Note that this will apply 'softmax' to the logits.\n",
    "def cross_entropy_loss(x, y):\n",
    "    # Convert labels to int 64 for tf cross-entropy function.\n",
    "    y = tf.cast(y, tf.int32)\n",
    "    if (taskRunning==\"regression\"):\n",
    "        loss=tf.keras.losses.binary_crossentropy(y, x)\n",
    "    else:    \n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)\n",
    "    # Apply softmax to logits and compute cross-entropy.\n",
    "    # Average loss across the batch.\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# Accuracy metric.\n",
    "def accuracy(y_pred, y_true):\n",
    "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
    "\n",
    "# Accuracy metric.\n",
    "def accuracyAvg(y_pred):\n",
    "    print(y_pred.numpy().shape)\n",
    "    \n",
    "    #convert to 1D array\n",
    "    y_pred_1d_array= y_pred.ravel()\n",
    "    \n",
    "    accCalc= np.full(y_pred_1d_array.shape, 0)\n",
    "    delta=np.amax(real_y_1d_array)-np.amin(real_y_1d_array)\n",
    "    \n",
    "    for i in range(len(y_pred_1d_array)):\n",
    "        accCalc[i]= abs(delta-y_pred_1d_array[i] - real_y_1d_array[i])\n",
    "    \n",
    "    return accCalc\n",
    "\n",
    "# Stochastic gradient descent optimizer.\n",
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization process. \n",
    "def run_optimization(x, y):\n",
    "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
    "    with tf.GradientTape() as g:\n",
    "        # Forward pass.\n",
    "        pred = neural_net(x, is_training=True)\n",
    "        # Compute loss.\n",
    "        loss = cross_entropy_loss(pred, y)\n",
    "        \n",
    "    # Variables to update, i.e. trainable variables.\n",
    "    trainable_variables = neural_net.trainable_variables\n",
    "\n",
    "    # Compute gradients.\n",
    "    gradients = g.gradient(loss, trainable_variables)\n",
    "    \n",
    "    # Update W and b following gradients.\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "def live_plot(steps, accuracy, figsize=(7,5), title=''):\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.xlim(0, training_steps)\n",
    "    plt.ylim(0, 100)\n",
    "    steps= [float(i) for i in steps]\n",
    "    accuracy= [float(i) for i in accuracy]\n",
    "    \n",
    "    m=0\n",
    "    if len(steps) > 1:\n",
    "        plt.scatter(steps,accuracy, label='accuracy', color='k') \n",
    "        m, b = np.polyfit(steps, accuracy, 1)\n",
    "        plt.plot(steps, [x * m for x in steps] + b)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy %')\n",
    "    #plt.legend(loc='center left') # the plot evolves to the right\n",
    "    plt.show();\n",
    "    return m\n",
    "\n",
    "def ETC(start, steps):\n",
    "    time_elapsed = datetime.now() - start\n",
    "    eta= (training_steps-steps) / display_step * time_elapsed\n",
    "    #avgString = str(avg).split(\".\")[0]\n",
    "    \n",
    "    hours= int(eta.seconds/3600)\n",
    "    minutes= int((eta.seconds/60)-hours*60)\n",
    "    seconds = int(eta.seconds - minutes*60 -hours*3600)\n",
    "    return \"%sh, %s min and %s sec\" % (hours, minutes, seconds)\n",
    "\n",
    "def elapsedTime(elapsed):\n",
    "    hours= int(elapsed.seconds/3600)\n",
    "    minutes= int((elapsed.seconds/60)-hours*60)\n",
    "    seconds = int(elapsed.seconds - minutes*60 -hours*3600)\n",
    "    return \"%sh, %s min and %s sec\" % (hours, minutes, seconds)\n",
    "\n",
    "def progress(percent=0, width=30):\n",
    "    left = width * percent // 100\n",
    "    right = width - left\n",
    "    print('\\r[', '#' * left, ' ' * right, ']',\n",
    "          f' {percent:.0f}%\\n',\n",
    "          sep='', end='', flush=True)\n",
    "    \n",
    "def measureSkewness(series):    \n",
    "    result=\"\"\n",
    "    \n",
    "    if (series.skew() > 1 or series.skew() < -1):\n",
    "        result=\"Highly skewed distribution\"\n",
    "    elif((0.5 < series.skew() < 1) or (-1 < series.skew() < -0.5)):\n",
    "        result=\"Moderately skewed distribution\"\n",
    "    elif(-0.5 < series.skew() < 0.5):\n",
    "        result=\"Approximately symmetric distribution\"\n",
    "    result = result +\" ( \" +str(round(series.skew(),2))+\" )\"\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##############################] 100%\n",
      "\n",
      "================= Iteration Stats ================\n",
      "                   step: 5000 of 5000\n",
      "                   loss: 0.655206\n",
      "\n",
      "          step accuracy: 72.00 %\n",
      "                    AVG: 76.32 %\n",
      "                   Best: 86.00 %\n",
      "\n",
      "            Trend slope: -0.000\n",
      "         MAD Dispersion: nan\n",
      "               Skewness: Approximately symmetric distribution ( -0.21 )\n",
      "\n",
      "================= Time           ================\n",
      "                Elapsed: 0h, 0 min and 47 sec\n",
      "                    ETC: 0h, 0 min and 0 sec\n",
      "\n",
      "================= Network Setup  ================\n",
      "      number of classes: 1\n",
      "     number of features: 14\n",
      "          learning rate: 1e-07\n",
      "         training steps: 5000\n",
      "             batch size: 100\n",
      "1st layer n. of neurons: 256\n",
      "2st layer n. of neurons: 256\n",
      "        Normalized data: True, type: max, Discrete Binary 0/1\n",
      "\n",
      "Trainning Analysis Finished. Start testing test dataset...\n",
      "\n",
      "Accuracy of highest score in prediction dataset\n",
      "         Test Accuracy: 76.00 %\n"
     ]
    }
   ],
   "source": [
    "# Run training for the given number of steps.\n",
    "avgCounter=0\n",
    "avg=0.0\n",
    "\n",
    "steps=[]\n",
    "accuracyValue=[]\n",
    "\n",
    "start_time = datetime.now()\n",
    "totalStartTime=start_time\n",
    "    \n",
    "live_plot([0], [0])\n",
    "print(\"analysis started. Waiting for preliminary data. One moment please...\")\n",
    "progress(0) \n",
    "\n",
    "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
    "    # Run the optimization to update W and b values.\n",
    "    run_optimization(batch_x, batch_y)\n",
    "        \n",
    "    if step % display_step == 0 or step==training_steps:\n",
    "        pred = neural_net(batch_x, is_training=True)\n",
    "        loss = cross_entropy_loss(pred, batch_y)\n",
    "        acc = accuracy(pred, batch_y)\n",
    "        avgCounter+=1\n",
    "        avg+=acc*100\n",
    "        \n",
    "        steps.append(step)\n",
    "        accuracyValue.append(acc*100)\n",
    "        trendSlope= live_plot(steps, accuracyValue)\n",
    "        totalTime =datetime.now()- totalStartTime\n",
    "        \n",
    "        stats=pd.Series(accuracyValue)\n",
    "        \n",
    "        if int(step/training_steps*100)<100:\n",
    "            print(\"Running...\")\n",
    "        progress(int(step/training_steps*100)) \n",
    "        print(\"\")\n",
    "        print(\"================= Iteration Stats ================\")\n",
    "        print(\"                   step: %i of %i\" % (step,training_steps))\n",
    "        print(\"                   loss: %f\" % loss)\n",
    "        print(\"\")\n",
    "        print(\"          step accuracy: %.2f %%\" %  (acc*100))\n",
    "        print(\"                    AVG: %.2f %%\" % (avg/avgCounter))\n",
    "        print(\"                   Best: %.2f %%\" % (np.max(accuracyValue)))\n",
    "        print(\"\")\n",
    "        print(\"            Trend slope: %.3f\" % (trendSlope))\n",
    "        print(\"         MAD Dispersion: \" + str(stats.mad()))\n",
    "        print(\"               Skewness: \" + measureSkewness(stats))\n",
    "        print(\"\")\n",
    "        print(\"================= Time           ================\")\n",
    "        print(\"                Elapsed: \" + elapsedTime(totalTime))\n",
    "        print(\"                    ETC: \" + ETC(start_time,step))\n",
    "        print(\"\")\n",
    "        print(\"================= Network Setup  ================\")\n",
    "        print(\"      number of classes: \"+ str(num_classes))\n",
    "        print(\"     number of features: \"+ str(num_features)) \n",
    "\n",
    "        print(\"          learning rate: \"+ str(learning_rate))\n",
    "        print(\"         training steps: \"+ str(training_steps))\n",
    "        print(\"             batch size: \"+ str(batch_size))\n",
    "\n",
    "        print(\"1st layer n. of neurons: \"+ str(n_hidden_1 ))\n",
    "        print(\"2st layer n. of neurons: \"+ str(n_hidden_2))\n",
    "        print(\"        Normalized data: \" + (\"True\" if normalizeDataValues else \"False\") +\", type: \" + normalizationType +\", \" +(\"Discrete Binary 0/1\" if normalizationTypeBinary else \"Continuous range [0,1]\"))\n",
    "\n",
    "        start_time = datetime.now()\n",
    "print(\"\")\n",
    "print(\"Trainning Analysis Finished. Start testing test dataset...\")\n",
    "print(\"\")\n",
    "run_test = neural_net(x_test, is_training=False)\n",
    "print(\"Accuracy of highest score in prediction dataset\")\n",
    "print(\"         Test Accuracy: %.2f %%\" % (tf.math.round(100*accuracy(run_test, y_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution of values:\n",
      "      equal to 1: 0.0%\n",
      "      equal to 0: 100.0%\n",
      "\n",
      "checking answers:\n",
      "none of the answers matches the output. Answer starts with: \n",
      "       '0 0 1 ...' -> matches [80]: 79.21% of values\n",
      "       '1 0 1 ...' -> matches [55]: 54.46% of values\n",
      "       '1 1 0 ...' -> matches [21]: 20.79% of values\n",
      "       '2 1 0 ...' -> matches [15]: 14.85% of values\n"
     ]
    }
   ],
   "source": [
    "def calStats(output, answer):\n",
    "    num_matches= np.sum(output[:min(len(output), len(answer))] == answer[:min(len(output), len(answer))])\n",
    "    percentage =round((num_matches / min(len(output), answer.shape[1]))*100,2)\n",
    "    return num_matches, percentage\n",
    "\n",
    "run_prediction = neural_net(data_predict_x, is_training=False)\n",
    "output_pre=np.round(run_prediction.numpy(),0)\n",
    "\n",
    "#assessing output value with its probability \n",
    "output = np.empty(shape=(output_pre.shape[0],1))\n",
    "for i in range(output_pre.shape[0]):\n",
    "    if ((output_pre[i][0]==1 and output_pre[i][1]==0) or (output_pre[i][0]==0 and output_pre[i][1]==1)):\n",
    "        output[i][0]=0\n",
    "    elif((output_pre[i][0]==1 and output_pre[i][1]==1) or (output_pre[i][0]==0 and output_pre[i][1]==0)):\n",
    "        output[i][0]=1\n",
    "\n",
    "print(\"distribution of values:\")\n",
    "print(\"      equal to 1: \" + str( round(np.sum(output==1)/output.shape[0]*100,1) )+\"%\")\n",
    "print(\"      equal to 0: \" + str( round(np.sum(output==0)/output.shape[0]*100,1) )+\"%\")\n",
    "\n",
    "#checking answers\n",
    "answer1=np.array([[0,0,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,1,0,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,1]])\n",
    "answer2=np.array([[1,0,1,1,1,1,0,0,1,0,0,1,0,0,1,1,0,1,0,0,0,0,1,0,1,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,0,0,0,1,0,1,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,1,1,0,0,1,0,1,0,1,0,1,0,1,0,1,1,1,1,1,1,1,0,1,1,0,1,1,0,1,1]])\n",
    "answer3=np.array([[1,1,0,1,0,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,1,0,1,1,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,0,1,0,0,1,1,0,1,0,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,0,1,1,0]])\n",
    "answer4=np.array([[2,1,0,2,0,1,0,2,1,2,1,2,1,1,2,1,1,1,1,2,0,1,3,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,3,1,1,1,1,1,2,1,0,1,1,1,0,1,1,2,1,3,1,1,1,0,0,1,1,2,1,1,1,1,1,1,1,2,1,2,0,1,1,2,1,0,0,2,1,1,1,2,0,1,1,1,1,1,2,1,1,0,1,1,0,3,1,0]])\n",
    "\n",
    "print(\"\")\n",
    "print(\"checking answers:\")\n",
    "\n",
    "if (output==answer1).all():\n",
    "    print(\"answwer starts with '0 0 1'\")\n",
    "elif (output==answer2).all():\n",
    "    print(\"answwer starts with '1 0 1'\")\n",
    "elif (output==answer3).all():\n",
    "    print(\"answwer starts with '1 1 0'\")\n",
    "elif (output==answer4).all():\n",
    "    print(\"answwer starts with '2 1 0'\")\n",
    "else:\n",
    "    print(\"none of the answers matches the output. Answer starts with: \")\n",
    "    num_matches, percentage= calStats(output, answer1)\n",
    "    print (\"       '0 0 1 ...' -> matches [\"+ str(num_matches)+\"]: \"+ str(percentage) +\"% of values\")\n",
    "    num_matches, percentage= calStats(output, answer2)\n",
    "    print (\"       '1 0 1 ...' -> matches [\"+ str(num_matches)+\"]: \"+ str(percentage) +\"% of values\")\n",
    "    num_matches, percentage= calStats(output, answer3)\n",
    "    print (\"       '1 1 0 ...' -> matches [\"+ str(num_matches)+\"]: \"+ str(percentage) +\"% of values\")\n",
    "    num_matches, percentage= calStats(output, answer4)\n",
    "    print (\"       '2 1 0 ...' -> matches [\"+ str(num_matches)+\"]: \"+ str(percentage) +\"% of values\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Author: Miguel Tom√°s \n",
    "\n",
    " License: Creative Commons \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
