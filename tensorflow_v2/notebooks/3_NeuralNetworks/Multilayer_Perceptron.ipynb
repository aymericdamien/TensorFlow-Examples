{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Example\n",
    "\n",
    "Build a 2-hidden layers fully connected neural network (a.k.a multilayer perceptron) with TensorFlow v2.\n",
    "\n",
    "This example is using a low-level approach to better understand all mechanics behind building neural networks and the training process.\n",
    "\n",
    "- Author: Miguel Tomás\n",
    "- Project: https://github.com/aeonSolutions/TensorFlow-Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Overview\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" alt=\"nn\" style=\"width: 400px;\"/>\n",
    "\n",
    "This example is using a file csv dataset.  \n",
    "\n",
    "In this example, each dataset will be converted to float32, normalized to [0, 1] and flattened to a 1-D array of \"num_features\" features \n",
    "\n",
    "More info: https://github.com/aeonSolutions/TensorFlow-Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualize predictions.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters initialization.\n",
    "num_classes = 100 # total classes : number of output results\n",
    "num_features = 0 # data features : number of input variables on the dataset. a value of 0 loads from the dataset bellow\n",
    "\n",
    "# Training parameters.\n",
    "learning_rate = 1\n",
    "training_steps = 10000\n",
    "batch_size = 100\n",
    "display_step = 100\n",
    "\n",
    "#normalization of data\n",
    "normalizeDataValues=True\n",
    "normalizationType= \"mean\" # accepts: max, mean\n",
    "normalizationTypeBinary=True\n",
    "\n",
    "# Network parameters.\n",
    "n_hidden_1 = 512 # 1st layer number of neurons.\n",
    "n_hidden_2 = 512 # 2nd layer number of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions Data.\n",
    "df_predict_ds=pd.read_csv('./week3_exam_dataset_test.csv')\n",
    "\n",
    "data_predict_x = np.float32(df_predict_ds.values)\n",
    "\n",
    "# Training Data.\n",
    "df_tr=pd.read_csv('./week3_exam_dataset_train.csv')\n",
    "\n",
    "df_tr_raw_y= df_tr['y']\n",
    "if num_classes==0:\n",
    "    num_classes= df_tr_raw_y.shape[0]\n",
    "\n",
    "df_tr_raw_values_y = df_tr_raw_y.values\n",
    "data_tr_y = np.float32(df_tr_raw_values_y)\n",
    "\n",
    "df_tr_raw_x= df_tr.drop('y',1)\n",
    "if num_features==0:\n",
    "    num_features= df_tr_raw_x.shape[1]\n",
    "else:\n",
    "    rs=\"\"\n",
    "    #TODO: fill possible empty values on the datasets\n",
    "df_tr_raw_values_x = df_tr_raw_x.values\n",
    "data_tr_x = np.float32(df_tr_raw_values_x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_tr_raw_x, df_tr_raw_y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Convert to float32.\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "# Convert to float32.\n",
    "y_train, y_test = np.array(y_train, np.float32), np.array(y_test, np.float32)\n",
    "\n",
    "# Normalize data values to [0, 1] interval.\n",
    "if normalizeDataValues:\n",
    "    if normalizationType==\"max\":\n",
    "        maxVal_train=np.amax(x_train, axis=0)\n",
    "        maxVal_test=np.amax(x_test, axis=0)\n",
    "        maxVal_pred=np.amax(data_predict_x, axis=0)\n",
    "        maxVal=max(np.amax(maxVal_train, axis=0),np.amax(maxVal_test, axis=0),np.amax(maxVal_pred, axis=0))\n",
    "        if normalizationTypeBinary:\n",
    "            x_train, x_test,data_predict_x = np.where((x_train / maxVal_train)>=0.5,1,0), np.where((x_test / maxVal_test)>=0.5,1,0), np.where((data_predict_x / maxVal_pred)>=0.5,1,0)\n",
    "        else:\n",
    "            x_train, x_test, data_predict_x = x_train / maxVal_train, x_test / maxVal_test, data_predict_x / maxVal_pred\n",
    "    else:\n",
    "        meanVal_test=np.mean(x_test, axis=0)\n",
    "        meanVal_train=np.mean(x_train, axis=0)\n",
    "        meanVal_pred=np.mean(data_predict_x, axis=0)\n",
    "        meanVal=max(np.amax(meanVal_train, axis=0),np.amax(meanVal_test, axis=0),np.amax(meanVal_pred, axis=0))\n",
    "        \n",
    "        if normalizationTypeBinary:\n",
    "            x_train, x_test,data_predict_x = np.where((x_train / meanVal_train)>=0.5,1,0), np.where((x_test / meanVal_test)>=0.5,1,0), np.where((data_predict_x / meanVal_pred)>=0.5,1,0)\n",
    "        else:\n",
    "            x_train, x_test, data_predict_x = x_train / meanVal_train, x_test / meanVal_test, data_predict_x / meanVal_pred\n",
    "\n",
    "# Use tf.data API to shuffle and batch data.\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF Model.\n",
    "class NeuralNet(Model):\n",
    "    # Set layers.\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # First fully-connected hidden layer.\n",
    "        self.fc1 = layers.Dense(n_hidden_1, activation=tf.nn.relu)\n",
    "        # First fully-connected hidden layer.\n",
    "        self.fc2 = layers.Dense(n_hidden_2, activation=tf.nn.relu)\n",
    "        # Second fully-connecter hidden layer.\n",
    "        self.out = layers.Dense(num_classes)\n",
    "\n",
    "    # Set forward pass.\n",
    "    def call(self, x, is_training=False):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        if not is_training:\n",
    "            # tf cross entropy expect logits without softmax, so only\n",
    "            # apply softmax when not training.\n",
    "            x = tf.nn.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Build neural network model.\n",
    "neural_net = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Entropy Loss.\n",
    "# Note that this will apply 'softmax' to the logits.\n",
    "def cross_entropy_loss(x, y):\n",
    "    # Convert labels to int 64 for tf cross-entropy function.\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    # Apply softmax to logits and compute cross-entropy.\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)\n",
    "    # Average loss across the batch.\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# Accuracy metric.\n",
    "def accuracy(y_pred, y_true):\n",
    "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
    "\n",
    "# Accuracy metric.\n",
    "def accuracyAvg(y_pred):\n",
    "    print(y_pred.numpy().shape)\n",
    "    \n",
    "    #convert to 1D array\n",
    "    y_pred_1d_array= y_pred.ravel()\n",
    "    \n",
    "    accCalc= np.full(y_pred_1d_array.shape, 0)\n",
    "    delta=np.amax(real_y_1d_array)-np.amin(real_y_1d_array)\n",
    "    \n",
    "    for i in range(len(y_pred_1d_array)):\n",
    "        accCalc[i]= abs(delta-y_pred_1d_array[i] - real_y_1d_array[i])\n",
    "    \n",
    "    return accCalc\n",
    "\n",
    "# Stochastic gradient descent optimizer.\n",
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization process. \n",
    "def run_optimization(x, y):\n",
    "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
    "    with tf.GradientTape() as g:\n",
    "        # Forward pass.\n",
    "        pred = neural_net(x, is_training=True)\n",
    "        # Compute loss.\n",
    "        loss = cross_entropy_loss(pred, y)\n",
    "        \n",
    "    # Variables to update, i.e. trainable variables.\n",
    "    trainable_variables = neural_net.trainable_variables\n",
    "\n",
    "    # Compute gradients.\n",
    "    gradients = g.gradient(loss, trainable_variables)\n",
    "    \n",
    "    # Update W and b following gradients.\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "def live_plot(steps, accuracy, figsize=(7,5), title=''):\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.xlim(0, training_steps)\n",
    "    plt.ylim(0, 100)\n",
    "    steps= [float(i) for i in steps]\n",
    "    accuracy= [float(i) for i in accuracy]\n",
    "    \n",
    "    m=0\n",
    "    if len(steps) > 1:\n",
    "        plt.scatter(steps,accuracy, label='accuracy', color='k') \n",
    "        m, b = np.polyfit(steps, accuracy, 1)\n",
    "        plt.plot(steps, [x * m for x in steps] + b)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy %')\n",
    "    #plt.legend(loc='center left') # the plot evolves to the right\n",
    "    plt.show();\n",
    "    return m\n",
    "\n",
    "def ETC(start, steps):\n",
    "    time_elapsed = datetime.now() - start\n",
    "    eta= (training_steps-steps) / display_step * time_elapsed\n",
    "    #avgString = str(avg).split(\".\")[0]\n",
    "    \n",
    "    hours= int(eta.seconds/3600)\n",
    "    minutes= int((eta.seconds/60)-hours*60)\n",
    "    seconds = int(eta.seconds - minutes*60 -hours*3600)\n",
    "    return \"%sh, %s min and %s sec\" % (hours, minutes, seconds)\n",
    "\n",
    "def elapsedTime(elapsed):\n",
    "    hours= int(elapsed.seconds/3600)\n",
    "    minutes= int((elapsed.seconds/60)-hours*60)\n",
    "    seconds = int(elapsed.seconds - minutes*60 -hours*3600)\n",
    "    return \"%sh, %s min and %s sec\" % (hours, minutes, seconds)\n",
    "\n",
    "def progress(percent=0, width=30):\n",
    "    left = width * percent // 100\n",
    "    right = width - left\n",
    "    print('\\r[', '#' * left, ' ' * right, ']',\n",
    "          f' {percent:.0f}%\\n',\n",
    "          sep='', end='', flush=True)\n",
    "    \n",
    "def measureSkewness(series):    \n",
    "    result=\"\"\n",
    "    \n",
    "    if (series.skew() > 1 or series.skew() < -1):\n",
    "        result=\"Highly skewed distribution\"\n",
    "    elif((0.5 < series.skew() < 1) or (-1 < series.skew() < -0.5)):\n",
    "        result=\"Moderately skewed distribution\"\n",
    "    elif(-0.5 < series.skew() < 0.5):\n",
    "        result=\"Approximately symmetric distribution\"\n",
    "    result = result +\" ( \" +str(round(series.skew(),2))+\" )\"\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##############################] 100%\n",
      "\n",
      "================= Iteration Stats ================\n",
      "                   step: 10000 of 10000\n",
      "                   loss: 0.341034\n",
      "\n",
      "               accuracy: 85.00 %\n",
      "                    AVG: 81.03 %\n",
      "                   Best: 88.00 %\n",
      "\n",
      "            Trend slope: 0.000\n",
      "         MAD Dispersion: nan\n",
      "               Skewness: Moderately skewed distribution ( -0.6 )\n",
      "\n",
      "================= Time           ================\n",
      "                Elapsed: 0h, 2 min and 17 sec\n",
      "                    ETC: 0h, 0 min and 0 sec\n",
      "\n",
      "================= Network Setup  ================\n",
      "      number of classes: 100\n",
      "     number of features: 14\n",
      "          learning rate: 1\n",
      "         training steps: 10000\n",
      "             batch size: 100\n",
      "1st layer n. of neurons: 512\n",
      "2st layer n. of neurons: 512\n",
      "        Normalized data: True, type: mean, Discrete Binary 0/1\n",
      "\n",
      "Analysis finished.\n"
     ]
    }
   ],
   "source": [
    "# Run training for the given number of steps.\n",
    "avgCounter=0\n",
    "avg=0.0\n",
    "\n",
    "steps=[]\n",
    "accuracyValue=[]\n",
    "\n",
    "start_time = datetime.now()\n",
    "totalStartTime=start_time\n",
    "    \n",
    "live_plot([0], [0])\n",
    "print(\"analysis started. Waiting for preliminary data. One moment please...\")\n",
    "progress(0) \n",
    "\n",
    "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
    "    # Run the optimization to update W and b values.\n",
    "    run_optimization(batch_x, batch_y)\n",
    "        \n",
    "    if step % display_step == 0:\n",
    "        pred = neural_net(batch_x, is_training=True)\n",
    "        loss = cross_entropy_loss(pred, batch_y)\n",
    "        acc = accuracy(pred, batch_y)\n",
    "        avgCounter+=1\n",
    "        avg+=acc*100\n",
    "        \n",
    "        steps.append(step)\n",
    "        accuracyValue.append(acc*100)\n",
    "        trendSlope= live_plot(steps, accuracyValue)\n",
    "        totalTime =datetime.now()- totalStartTime\n",
    "        \n",
    "        stats=pd.Series(accuracyValue)\n",
    "        \n",
    "        if int(step/training_steps*100)<100:\n",
    "            print(\"Running...\")\n",
    "        progress(int(step/training_steps*100)) \n",
    "        print(\"\")\n",
    "        print(\"================= Iteration Stats ================\")\n",
    "        print(\"                   step: %i of %i\" % (step,training_steps))\n",
    "        print(\"                   loss: %f\" % loss)\n",
    "        print(\"\")\n",
    "        print(\"               accuracy: %.2f %%\" %  (acc*100))\n",
    "        print(\"                    AVG: %.2f %%\" % (avg/avgCounter))\n",
    "        print(\"                   Best: %.2f %%\" % (np.max(accuracyValue)))\n",
    "        print(\"\")\n",
    "        print(\"            Trend slope: %.3f\" % (trendSlope))\n",
    "        print(\"         MAD Dispersion: \" + str(stats.mad()))\n",
    "        print(\"               Skewness: \" + measureSkewness(stats))\n",
    "        print(\"\")\n",
    "        print(\"================= Time           ================\")\n",
    "        print(\"                Elapsed: \" + elapsedTime(totalTime))\n",
    "        print(\"                    ETC: \" + ETC(start_time,step))\n",
    "        print(\"\")\n",
    "        print(\"================= Network Setup  ================\")\n",
    "        print(\"      number of classes: \"+ str(num_classes))\n",
    "        print(\"     number of features: \"+ str(num_features)) \n",
    "\n",
    "        print(\"          learning rate: \"+ str(learning_rate))\n",
    "        print(\"         training steps: \"+ str(training_steps))\n",
    "        print(\"             batch size: \"+ str(batch_size))\n",
    "\n",
    "        print(\"1st layer n. of neurons: \"+ str(n_hidden_1 ))\n",
    "        print(\"2st layer n. of neurons: \"+ str(n_hidden_2))\n",
    "        print(\"        Normalized data: \" + (\"True\" if normalizeDataValues else \"False\") +\", type: \" + normalizationType +\", \" +(\"Discrete Binary 0/1\" if normalizationType else \"Continuous range [0,1]\"))\n",
    "\n",
    "        start_time = datetime.now()\n",
    "print(\"\")\n",
    "print(\"Analysis finished.\")        \n",
    "#print(\"Final Average accuracy is %.2f %%\" % (avg/avgCounter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#!!! code bellow this line is not yet finished !!!\n",
    "# +++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "# Test model on validation set.\n",
    "print(x_test.shape)\n",
    "\n",
    "pred = neural_net(x_test, is_training=False)\n",
    "\n",
    "print(\"Accuracy of highest score in prediction vector\")\n",
    "print(\"         Test Accuracy: %.2f %%\" % (tf.math.round(100*accuracy(pred, y_test))))\n",
    "print(\"\")\n",
    "\n",
    "prediction= np.round(pred.numpy(),2)\n",
    "print(\"Model prediction shape:\"  + str(prediction.shape))\n",
    "print(\"   Model initial shape:\"  + str(y_test.shape))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Model prediction value:\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = neural_net(data_predict_x)\n",
    "print(\"Model prediction: %i\" % np.argmax(predictions.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Author: Miguel Tomás \n",
    "\n",
    " License: Creative Commons \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
