{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Example\n",
    "\n",
    "Build a 2-hidden layers fully connected neural network (a.k.a multilayer perceptron) with TensorFlow v2.\n",
    "\n",
    "This example is using a low-level approach to better understand all mechanics behind building neural networks and the training process.\n",
    "\n",
    "- Author: Miguel Tomás\n",
    "- Project: https://github.com/aeonSolutions/TensorFlow-Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Overview\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" alt=\"nn\" style=\"width: 400px;\"/>\n",
    "\n",
    "This example is using a file csv dataset.  \n",
    "\n",
    "In this example, each dataset will be converted to float32, normalized to [0, 1] and flattened to a 1-D array of \"num_features\" features \n",
    "\n",
    "More info: https://github.com/aeonSolutions/TensorFlow-Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualize predictions.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters initialization.\n",
    "num_classes = 0 # total classes : number of output varibales\n",
    "num_features = 1 # data features : number of input variables > load from the dataset bellow\n",
    "\n",
    "# Training parameters.\n",
    "learning_rate = 0.001\n",
    "training_steps = 1000\n",
    "batch_size = 256\n",
    "display_step = 100\n",
    "\n",
    "# Network parameters.\n",
    "n_hidden_1 = 64 # 1st layer number of neurons.\n",
    "n_hidden_2 = 64 # 2nd layer number of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions Data.\n",
    "df_predict_ds=pd.read_csv('./week3_exam_dataset_test.csv')\n",
    "\n",
    "data_predict_x = np.float32(df_predict_ds.values)\n",
    "\n",
    "# Training Data.\n",
    "df_tr=pd.read_csv('./week3_exam_dataset_train.csv')\n",
    "\n",
    "df_tr_raw_y= df_tr['y']\n",
    "num_classes= df_tr_raw_y.shape[0]\n",
    "if num_features==0:\n",
    "    num_features= df_tr_raw_y.shape[0]\n",
    "\n",
    "df_tr_raw_values_y = df_tr_raw_y.values\n",
    "data_tr_y = np.float32(df_tr_raw_values_y)\n",
    "\n",
    "df_tr_raw_x= df_tr.drop('y',1)\n",
    "df_tr_raw_values_x = df_tr_raw_x.values\n",
    "data_tr_x = np.float32(df_tr_raw_values_x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_tr_raw_x, df_tr_raw_y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Convert to float32.\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "# Convert to float32.\n",
    "y_train, y_test = np.array(y_train, np.float32), np.array(y_test, np.float32)\n",
    "\n",
    "# Normalize data values to [0, 1] interval.\n",
    "maxVal=max(np.amax(x_train),np.amax(x_test))\n",
    "x_train, x_test = x_train / maxVal, x_test / maxVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.data API to shuffle and batch data.\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF Model.\n",
    "class NeuralNet(Model):\n",
    "    # Set layers.\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # First fully-connected hidden layer.\n",
    "        self.fc1 = layers.Dense(n_hidden_1, activation=tf.nn.relu)\n",
    "        # First fully-connected hidden layer.\n",
    "        self.fc2 = layers.Dense(n_hidden_2, activation=tf.nn.relu)\n",
    "        # Second fully-connecter hidden layer.\n",
    "        self.out = layers.Dense(num_classes)\n",
    "\n",
    "    # Set forward pass.\n",
    "    def call(self, x, is_training=False):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        if not is_training:\n",
    "            # tf cross entropy expect logits without softmax, so only\n",
    "            # apply softmax when not training.\n",
    "            x = tf.nn.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Build neural network model.\n",
    "neural_net = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Entropy Loss.\n",
    "# Note that this will apply 'softmax' to the logits.\n",
    "def cross_entropy_loss(x, y):\n",
    "    # Convert labels to int 64 for tf cross-entropy function.\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    # Apply softmax to logits and compute cross-entropy.\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)\n",
    "    # Average loss across the batch.\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# Accuracy metric.\n",
    "def accuracy(y_pred, y_true):\n",
    "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
    "\n",
    "# Accuracy metric.\n",
    "def accuracyAvg(y_pred):\n",
    "    print(y_pred.numpy().shape)\n",
    "    \n",
    "    #convert to 1D array\n",
    "    y_pred_1d_array= y_pred.ravel()\n",
    "    \n",
    "    accCalc= np.full(y_pred_1d_array.shape, 0)\n",
    "    delta=np.amax(real_y_1d_array)-np.amin(real_y_1d_array)\n",
    "    \n",
    "    for i in range(len(y_pred_1d_array)):\n",
    "        accCalc[i]= abs(delta-y_pred_1d_array[i] - real_y_1d_array[i])\n",
    "    \n",
    "    return accCalc\n",
    "\n",
    "# Stochastic gradient descent optimizer.\n",
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization process. \n",
    "def run_optimization(x, y):\n",
    "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
    "    with tf.GradientTape() as g:\n",
    "        # Forward pass.\n",
    "        pred = neural_net(x, is_training=True)\n",
    "        # Compute loss.\n",
    "        loss = cross_entropy_loss(pred, y)\n",
    "        \n",
    "    # Variables to update, i.e. trainable variables.\n",
    "    trainable_variables = neural_net.trainable_variables\n",
    "\n",
    "    # Compute gradients.\n",
    "    gradients = g.gradient(loss, trainable_variables)\n",
    "    \n",
    "    # Update W and b following gradients.\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "def live_plot(steps, accuracy, figsize=(7,5), title=''):\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.xlim(0, training_steps)\n",
    "    plt.ylim(0, 100)\n",
    "    steps= [float(i) for i in steps]\n",
    "    accuracy= [float(i) for i in accuracy]\n",
    "    \n",
    "    if len(steps) > 1:\n",
    "        plt.scatter(steps,accuracy, label='accuracy', color='k') \n",
    "        m, b = np.polyfit(steps, accuracy, 1)\n",
    "        plt.plot(steps, [x * m for x in steps] + b)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy %')\n",
    "    #plt.legend(loc='center left') # the plot evolves to the right\n",
    "    plt.show();\n",
    "    \n",
    "def ETC(start, steps):\n",
    "    time_elapsed = datetime.now() - start\n",
    "    eta= (training_steps-steps) / display_step * time_elapsed\n",
    "    #avgString = str(avg).split(\".\")[0]\n",
    "    \n",
    "    hours= int(eta.seconds/3600)\n",
    "    minutes= int((eta.seconds/60)-hours*60)\n",
    "    seconds = int(eta.seconds - minutes*60 -hours*3600)\n",
    "    return \"%sh, %s min and %s sec\" % (hours, minutes, seconds)\n",
    "\n",
    "def elapsedTime(elapsed):\n",
    "    hours= int(elapsed.seconds/3600)\n",
    "    minutes= int((elapsed.seconds/60)-hours*60)\n",
    "    seconds = int(elapsed.seconds - minutes*60 -hours*3600)\n",
    "    return \"%sh, %s min and %s sec\" % (hours, minutes, seconds)\n",
    "\n",
    "def progress(percent=0, width=30):\n",
    "    left = width * percent // 100\n",
    "    right = width - left\n",
    "    print('\\r[', '#' * left, ' ' * right, ']',\n",
    "          f' {percent:.0f}%\\n',\n",
    "          sep='', end='', flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##############################] 100%\n",
      "\n",
      "================= Iteration Stats ================\n",
      "                   step: 1000 of 1000\n",
      "                   loss: 0.592776\n",
      "               accuracy: 79.30 %\n",
      "                    AVG: 75.23 %\n",
      "\n",
      "================= Time           ================\n",
      "                Elapsed: 0h, 3 min and 54 sec\n",
      "                    ETC: 0h, 0 min and 0 sec\n",
      "\n",
      "================== Network Setup ================\n",
      "      number of classes: 32460\n",
      "     number of features: 1\n",
      "          learning rate: 0.001\n",
      "         training steps: 1000\n",
      "             batch size: 256\n",
      "1st layer n. of neurons: 64\n",
      "2st layer n. of neurons: 64\n",
      "\n",
      "Analysis finished.\n",
      "Final Average accuracy is 75.23 %\n"
     ]
    }
   ],
   "source": [
    "# Run training for the given number of steps.\n",
    "avgCounter=0\n",
    "avg=0.0\n",
    "\n",
    "steps=[]\n",
    "accuracyValue=[]\n",
    "\n",
    "start_time = datetime.now()\n",
    "totalStartTime=start_time\n",
    "    \n",
    "live_plot([0], [0])\n",
    "print(\"analysis started. Waiting for preliminary data. One moment please...\")\n",
    "progress(0) \n",
    "\n",
    "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
    "    # Run the optimization to update W and b values.\n",
    "    run_optimization(batch_x, batch_y)\n",
    "        \n",
    "    if step % display_step == 0:\n",
    "        pred = neural_net(batch_x, is_training=True)\n",
    "        loss = cross_entropy_loss(pred, batch_y)\n",
    "        acc = accuracy(pred, batch_y)\n",
    "        avgCounter+=1\n",
    "        avg+=acc*100\n",
    "        \n",
    "        steps.append(step)\n",
    "        accuracyValue.append(acc*100)\n",
    "        live_plot(steps, accuracyValue)\n",
    "        totalTime =datetime.now()- totalStartTime\n",
    "        \n",
    "        if int(step/training_steps*100)<100:\n",
    "            print(\"Running...\")\n",
    "        progress(int(step/training_steps*100)) \n",
    "        print(\"\")\n",
    "        print(\"================= Iteration Stats ================\")\n",
    "        print(\"                   step: %i of %i\" % (step,training_steps))\n",
    "        print(\"                   loss: %f\" % loss)\n",
    "        print(\"               accuracy: %.2f %%\" %  (acc*100))\n",
    "        print(\"                    AVG: %.2f %%\" % (avg/avgCounter))\n",
    "        print(\"\")\n",
    "        print(\"================= Time           ================\")\n",
    "        print(\"                Elapsed: \" + elapsedTime(totalTime))\n",
    "        print(\"                    ETC: \" + ETC(start_time,step))\n",
    "        print(\"\")\n",
    "        print(\"================= Network Setup  ================\")\n",
    "        print(\"      number of classes: \"+ str(num_classes))\n",
    "        print(\"     number of features: \"+ str(num_features)) \n",
    "\n",
    "        print(\"          learning rate: \"+ str(learning_rate))\n",
    "        print(\"         training steps: \"+ str(training_steps))\n",
    "        print(\"             batch size: \"+ str(batch_size))\n",
    "\n",
    "        print(\"1st layer n. of neurons: \"+ str(n_hidden_1 ))\n",
    "        print(\"2st layer n. of neurons: \"+ str(n_hidden_2))\n",
    "\n",
    "        start_time = datetime.now()\n",
    "print(\"\")\n",
    "print(\"Analysis finished.\")        \n",
    "#print(\"Final Average accuracy is %.2f %%\" % (avg/avgCounter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "#!!! code bellow this line is not yet finished !!!\n",
    "# +++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "# Test model on validation set.\n",
    "print(x_test.shape)\n",
    "\n",
    "pred = neural_net(x_test, is_training=False)\n",
    "\n",
    "print(\"Accuracy of highest score in prediction vector\")\n",
    "print(\"         Test Accuracy: %.2f %%\" % (tf.math.round(100*accuracy(pred, y_test))))\n",
    "print(\"\")\n",
    "\n",
    "prediction= np.round(pred.numpy(),2)\n",
    "print(\"Model prediction shape:\"  + str(prediction.shape))\n",
    "print(\"   Model initial shape:\"  + str(y_test.shape))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Model prediction value:\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = neural_net(data_predict_x)\n",
    "print(\"Model prediction: %i\" % np.argmax(predictions.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Author: Miguel Tomás \n",
    "\n",
    " License: Creative Commons \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
